{
	"auto_complete":
	{
		"selected_items":
		[
		]
	},
	"buffers":
	[
		{
			"file": "utils/loadcoraldata_utils.py",
			"settings":
			{
				"buffer_size": 27184,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_generator.py",
			"settings":
			{
				"buffer_size": 26758,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_layers.py",
			"settings":
			{
				"buffer_size": 5869,
				"line_ending": "Windows"
			}
		},
		{
			"contents": "import keras.backend as K\nimport numpy as np\nfrom keras.layers import (\n    Dropout,\n    Lambda,\n    Activation,\n    Dense,\n    Flatten,\n    concatenate\n)\nfrom keras.layers.convolutional import (\n    Conv2D,\n    Conv2DTranspose,\n    MaxPooling2D,\n    AveragePooling2D,\n    ZeroPadding2D\n)\nfrom keras.layers.merge import add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom NeMO_layers import CroppingLike2D, BilinearUpSampling2D\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\n# General multi-purpose convolution block used for all convolutions\n# filters: # of filters [int]\n# kernel_size: Size of convolutional kernel [(int,int)]\n# conv_strides: Stride of convolution kernel [(int,int)]\n# padding: Type of padding for convolution ['valid' or 'same']\n# pad_bool: Custom padding of the tensor [bool]\n# pad_size: Custom padding size for the tensor [(int,int)]\n# pool_size: Max pooling size [(int,int)]\n# pool_strides: Max pooling stride size [(int,int)], usually same as pool_size\n# dilation_rate: Convolution kernel dilation rate [(int,int)]\n# layercombo: Combination of layers: ['c': Convolution, 'a': Activation, 'p': Pooling, 'b': Batch Normalization]\n# weight_decay: kernel regularizer l2 weight decay [float]\n# block_name: Name of block [string]\ndef alex_conv(filters, kernel_size, conv_strides=(1,1), padding='valid', pad_bool=False, pad_size=(0,0), \n  pool_size=(2,2), pool_strides=(2,2), dilation_rate=(1,1), layercombo='capb', weight_decay=0., block_name='alexblock'):\n    def f(input):\n      x = input\n      c_total = layercombo.count(\"c\")\n      a_total = layercombo.count(\"a\")\n      p_total = layercombo.count(\"p\")\n      b_total = layercombo.count(\"b\")\n      c_count=0\n      a_count=0\n      p_count=0\n      b_count=0\n      f = lambda input,c_count: input[c_count] if type(input) is list else input\n\n      for layer_char in layercombo:\n        if layer_char == \"c\":\n          if pad_bool:\n            x = ZeroPadding2D(padding=pad_size)(x)\n            test_size = dilation_rate[0]*(kernel_size[0]-1)+1   # have to make sure this size is smaller than x.size\n            if test_size > x.shape[1]:\n              temp_padsize = int(np.ceil((test_size-int(x.shape[1]))/2))\n              x = ZeroPadding2D(padding=(temp_padsize,temp_padsize))(x)   \n\n          x = Conv2D(f(filters,c_count), f(kernel_size,c_count), strides=conv_strides, padding=padding, dilation_rate=dilation_rate,\n            kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay), name='{}_conv{}'.format(block_name,c_count+1))(x)\n          c_count +=1\n\n        if layer_char == \"p\":\n          if pool_size[0] > x.shape[1]:\n            temp_padsize = int(np.ceil((pool_size[0]-int(x.shape[1]))/2))\n            x = ZeroPadding2D(padding=(temp_padsize,temp_padsize))(x)\n          x = MaxPooling2D(pool_size=pool_size, strides=pool_strides, name='{}_pool{}'.format(block_name,p_count+1))(x)\n          p_count +=1\n\n        if layer_char == \"b\":\n          x = BatchNormalization(name='{}_BatchNorm{}'.format(block_name, b_count+1))(x)\n          b_count +=1\n\n        if layer_char == \"a\":\n          x = Activation('relu', name='{}_Activ{}'.format(block_name, a_count+1))(x)\n          a_count +=1\n      return x\n    return f\n\ndef parallel_conv(filters, kernel_size, pad_size=(0,0), pool_size=(2,2), dilation_rate=(1,1), weight_decay=0., batchnorm_bool=False,\n  block_name='parallel_block'):\n    def f(input):\n      n = len(input)\n      x = input\n      factor = [int(x_i.shape[1]//x[0].shape[1]) for x_i in x]\n\n      for i in range(n):\n        pad_size_i = [factor[i]*k for k in pad_size]\n        dilation_rate_i = [factor[i]*k for k in dilation_rate]\n        # pool_size_i = [factor[i]//2*k for k in pool_size]\n\n        # NOTE!!! A list PASSES by reference, and hence will point to the same location!\n        x[i] = alex_conv(filters, kernel_size, pad_bool=True, pool_bool=True, batchnorm_bool=False, pad_size=pad_size_i,\n          pool_size=pool_size, pool_strides=pool_size, dilation_rate=dilation_rate_i, weight_decay=weight_decay, \n          block_name='{}_alexconv{}'.format(block_name,i+1))(x[i]) # first don't factor the pools, need to save them for later sections\n\n        if batchnorm_bool:\n          x[i] = BatchNormalization()(x[i])\n      return x\n    return f\n\ndef vgg_convblock(filters, kernel_size, convs=1, conv_strides=(1,1), padding='same', pad_bool=False, pool_bool=True, batchnorm_bool=False, pad_size=(0,0),\n  pool_size=(2,2), pool_strides=(2,2), dilation_rate=(1,1), weight_decay=0., block_name='vgg_convblock'):\n    def f(input):\n      x = input\n      for i in range(convs):\n        if i < convs-1:\n          x = alex_conv(filters, kernel_size, padding=padding, pad_bool=pad_bool, pool_bool=False, batchnorm_bool=False, pad_size=pad_size,\n            dilation_rate=dilation_rate, weight_decay=weight_decay, block_name='{}_alexconv{}'.format(block_name, int(i+1)))(x)\n        else:\n          x = alex_conv(filters, kernel_size, padding=padding, pad_bool=pad_bool, pool_bool=pool_bool, batchnorm_bool=batchnorm_bool, pad_size=pad_size,\n            pool_size=pool_size, pool_strides=pool_size, dilation_rate=dilation_rate, weight_decay=weight_decay, \n            block_name='{}_alexconv{}'.format(block_name, int(i+1)))(x)\n      return x\n    return f\n\ndef vgg_deconvblock(filters, kernel_size, classes, layercombo, target_shape=None, scale=1, weight_decay=0., block_name='vgg_deconvblock'):\n    def f(x, y):\n        x = alex_conv(filters, kernel_size, padding='same', pad_size=(0,0), dilation_rate=(1,1), layercombo=layercombo, \n          weight_decay=weight_decay, block_name='{}_alexconv'.format(block_name))(x)\n\n        x = Conv2D(classes, kernel_size=(1,1), activation='linear', padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n          name='{}_1b1conv'.format(block_name))(x)\n\n        if y is not None:\n          def scaling(xx, ss=1):\n            return xx * ss\n          scaled = Lambda(scaling, arguments={'ss': scale}, name='{}_scale'.format(block_name))(x)\n          x = add([y, scaled])\n\n        upscore = BilinearUpSampling2D(target_shape=target_shape, name='{}_BilinearUpsample'.format(block_name))(x)\n        return upscore\n    return f\n\n\ndef pool_concat(pool_size=(1,1), batchnorm_bool=False, block_name='poolconcat_block'):\n    def f(input):\n      n = len(input)\n      x = input\n      factor = [int(x_i.shape[1]//x[0].shape[1]) for x_i in x]\n\n      for i in range(n):\n        pool_size_i = [factor[i]*k for k in pool_size]\n        if pool_size_i[0] > x[i].shape[1]:\n          temp_padsize = int(np.ceil((pool_size_i[0]-int(x[i].shape[1]))/2))\n          x[i] = ZeroPadding2D(padding=(temp_padsize, temp_padsize))(x[i])\n        x[i] = MaxPooling2D(pool_size=pool_size_i, strides=pool_size_i, name='{}_pool{}'.format(block_name,i+1))(x[i])\n\n        if batchnorm_bool:\n          x[i] = BatchNormalization()(x[i])\n        if i!=0:\n          x[0] = concatenate([x[0],x[i]], name='{}_concat{}'.format(block_name,i))\n\n      return x[0]\n    return f\n\ndef alex_fc(filters, flatten_bool=False, dropout_bool=False, dropout=0.5, weight_decay=0., block_name='alexfc'):\n    def f(input):\n      x = input\n      if flatten_bool:\n        x = Flatten()(x)\n\n      x = Dense(filters, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay), name='{}_dense'.format(block_name))(x)\n      if dropout_bool:\n        x = Dropout(dropout)(x)\n      return x\n    return f\n\n\ndef vgg_fcblock(filters, full_layers, dropout_bool=False, dropout=0.5, weight_decay=0., block_name='vgg_fcblock'):\n    def f(input):\n      x = input\n\n      for i in range(full_layers):\n        x = Conv2D(filters[i], kernel_size=(1,1), activation='relu', padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n          name='{}_1b1conv{}'.format(block_name,i+1))(x)\n        if dropout_bool:\n          x = Dropout(dropout[i])(x)\n      return x\n    return f\n\ndef res_shortcut(input, residual, weight_decay=0):\n    \"\"\" Adds a shortcut between input and residual block and merges them with \"sum\"\n    \"\"\"\n    shortcut = input\n    input_shape = K.int_shape(input)\n    residual_shape = K.int_shape(residual)\n\n    stride_width = int(round(input_shape[1] / residual_shape[1]))\n    stride_height = int(round(input_shape[2] / residual_shape[2]))\n    equal_channels = input_shape[3] == residual_shape[3]\n\n    if stride_width > 1 or stride_height > 1 or not equal_channels:\n      shortcut = Conv2D(filters=residual_shape[3], kernel_size=(1,1), strides=(stride_width,stride_height),\n        padding=\"valid\", kernel_initializer=\"he_normal\", kernel_regularizer=l2(weight_decay))(input)\n\n    return add([shortcut, residual])\n\ndef res_initialconv(filters, init_kernel=(7,7), init_strides=(2,2), weight_decay=0., block_name='initblock'):\n    \"\"\" First basic convolution that gets everything started. \n    Format is Conv (/2) -> BN -> Actv -> Pool (/2)\n    \"\"\"\n    def f(input):\n      x = Conv2D(filters, init_kernel, strides=init_strides, padding='same',\n        kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n        name='{}_conv'.format(block_name))(input)\n      x = BatchNormalization()(x)\n      x = Activation('relu')(x)\n      x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\", name='{}_pool'.format(block_name))(x)\n      return x\n    return f\n\ndef res_basicconv(filters, convs=2, init_strides=(1,1), weight_decay=0., block_name='blockx'):\n    \"\"\" Basic 3 X 3 convolution blocks for use in resnets with layers <= 34.\n    Follows improved proposed scheme in hhttp://arxiv.org/pdf/1603.05027v2.pdf\n    Format is BN -> Actv -> Conv (/2, if first of block), except for the very first conv of first block (just Conv).\n    \"\"\"\n    def f(input):\n      for i in range(convs):\n        if i == 0:\n          x = input\n\n        if block_name =='megablock1_block1' and i==0:\n          x = Conv2D(filters, (3,3), strides=init_strides, padding='same',\n            kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n            name='{}_conv{}'.format(block_name, int(i+1)))(x)   # linear activation for very first conv of first block\n        else:\n          x = BatchNormalization()(x)\n          x = Activation('relu')(x)\n          if i==0:\n            x = Conv2D(filters, (3,3), strides=init_strides, padding='same', \n              kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n              name='{}_conv{}'.format(block_name, int(i+1)))(x)\n          else:\n            x = Conv2D(filters, (3,3), strides=(1,1), padding='same',\n              kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay),\n              name='{}_conv{}'.format(block_name, int(i+1)))(x)\n      return res_shortcut(input, x, weight_decay)\n    return f\n\ndef res_megaconv(filters, convs, reps, init_strides=(1,1), weight_decay=0., block_name='megablockx'):\n    \"\"\" Mega convolution block that combines multiple res_basicconv blocks. Note that init_strides must be defined for the first block\n        in case downsampling is necessary\n    \"\"\"\n    def f(input):\n      x = input\n      for i in range(reps):\n        if i == 0:\n          x = res_basicconv(filters, convs, init_strides=init_strides, weight_decay = weight_decay, block_name='{}_block{}'.format(block_name, int(i+1)))(x)\n        else:\n          x = res_basicconv(filters, convs, init_strides=(1,1), weight_decay = weight_decay, block_name='{}_block{}'.format(block_name, int(i+1)))(x)\n      return x\n    return f\n\ndef res_1b1conv(filters, convs, init_kernelsize=(1,1), init_dilationrate=(1,1), weight_decay=0., block_name='block1b1'):\n    \"\"\" 1x1xM convolution filter for resnet\n    \"\"\"\n    def f(input):\n      for i in range(convs):\n        if i==0:\n          x = BatchNormalization()(input)\n          x = Activation('relu')(x)\n          x = Conv2D(filters, kernel_size=init_kernelsize, padding='same', dilation_rate=init_dilationrate,\n            kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay), name='{}_1b1conv{}'.format(block_name,int(i+1)))(x)\n        else:\n          x = Activation('relu')(x)\n          x = Conv2D(filters, kernel_size=(1,1), activation='relu', padding='same',\n            kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay), name='{}_1b1conv{}'.format(block_name,int(i+1)))(x)\n      return x\n    return f\n\ndef res_fc(classes, weight_decay=0., block_name='blockfc'):\n    \"\"\" Fully connected layer for resnet\n    \"\"\"\n    def f(input):\n      block_shape = K.int_shape(input)\n      pool = AveragePooling2D(pool_size=(block_shape[1], block_shape[2]), strides=(1,1), name='{}_pool'.format(block_name))(input)\n      flatten = Flatten()(pool)\n      dense = Dense(units=classes, kernel_initializer='he_normal', kernel_regularizer=l2(weight_decay), name='{}_dense'.format(block_name))(flatten)\n      return dense\n    return f\n\n# ALL functions below are from the original VGG FCN code, but they are hard-coded in many ways (filters, # of layers, etc...)\n# Only really kept here for posterity\n\ndef vgg_conv(filters, convs, padding=False, weight_decay=0., block_name='blockx'):\n    \"\"\"A VGG convolutional block for encoding.\n    # NOTE: All kernels are 3x3 hard-coded!\n\n    :param filters: Integer, number of filters per conv layer\n    :param convs: Integer, number of conv layers in the block\n    :param block_name: String, the name of the block, e.g., block1\n\n    >>> from keras_fcn.blocks import vgg_conv\n    >>> x = vgg_conv(filters=64, convs=2, block_name='block1')(x)\n\n    \"\"\"\n    def f(x):\n        for i in range(convs):\n            if block_name == 'block1' and i == 0:\n                if padding is True:\n                    x = ZeroPadding2D(padding=(100, 100))(x)\n                x = Conv2D(filters, (3, 3), activation='relu', padding='same',\n                           kernel_initializer='he_normal',\n                           kernel_regularizer=l2(weight_decay),\n                           name='{}_conv{}'.format(block_name, int(i + 1)))(x)\n            else:\n                x = Conv2D(filters, (3, 3), activation='relu', padding='same',\n                           kernel_initializer='he_normal',\n                           kernel_regularizer=l2(weight_decay),\n                           name='{}_conv{}'.format(block_name, int(i + 1)))(x)\n\n        pool = MaxPooling2D((2, 2), strides=(2, 2), padding='same',\n                            name='{}_pool'.format(block_name))(x)\n        return pool\n    return f\n\n\ndef vgg_fc(filters, weight_decay=0., block_name='block5'):\n    \"\"\"A fully convolutional block for encoding.\n\n    :param filters: Integer, number of filters per fc layer\n\n    >>> from keras_fcn.blocks import vgg_fc\n    >>> x = vgg_fc(filters=4096)(x)\n\n    \"\"\"\n    def f(x):\n        fc6 = Conv2D(filters, kernel_size=(7, 7),\n                     activation='relu', padding='same',\n                     dilation_rate=(2, 2),\n                     kernel_initializer='he_normal',\n                     kernel_regularizer=l2(weight_decay),\n                     name='{}_fc6'.format(block_name))(x)\n        drop6 = Dropout(0.5)(fc6)\n        fc7 = Conv2D(filters, kernel_size=(1, 1),\n                     activation='relu', padding='same',\n                     kernel_initializer='he_normal',\n                     kernel_regularizer=l2(weight_decay),\n                     name='{}_fc7'.format(block_name))(drop6)\n        drop7 = Dropout(0.5)(fc7)\n        return drop7\n    return f\n\ndef vgg_deconv(classes, scale=1, kernel_size=(4, 4), strides=(2, 2),\n               crop_offset='centered', weight_decay=0., block_name='featx'):\n    \"\"\"A VGG convolutional transpose block for decoding.\n\n    :param classes: Integer, number of classes\n    :param scale: Float, scale factor to the input feature, varing from 0 to 1\n    :param kernel_size: Tuple, the kernel size for Conv2DTranspose layers\n    :param strides: Tuple, the strides for Conv2DTranspose layers\n    :param crop_offset: Tuple or \"centered\", the offset for cropping.\n    The default is \"centered\", which crop the center of the feature map.\n\n    >>> from keras_fcn.blocks import vgg_deconv\n    >>> x = vgg_deconv(classes=21, scale=1e-2, block_name='feat2')(x)\n\n    \"\"\"\n    def f(x, y):\n        def scaling(xx, ss=1):\n            return xx * ss\n        scaled = Lambda(scaling, arguments={'ss': scale},\n                        name='scale_{}'.format(block_name))(x)\n        score = Conv2D(filters=classes, kernel_size=(1, 1),\n                       activation='linear',\n                       kernel_initializer='he_normal',\n                       kernel_regularizer=l2(weight_decay),\n                       name='score_{}'.format(block_name))(scaled)\n        if y is None:\n            upscore = Conv2DTranspose(filters=classes, kernel_size=kernel_size,\n                                      strides=strides, padding='valid',\n                                      kernel_initializer='he_normal',\n                                      kernel_regularizer=l2(weight_decay),\n                                      use_bias=False,\n                                      name='upscore_{}'.format(block_name))(score)\n        else:\n            crop = CroppingLike2D(target_shape=K.int_shape(y),\n                                  offset=crop_offset,\n                                  name='crop_{}'.format(block_name))(score)\n            merge = add([y, crop])\n            upscore = Conv2DTranspose(filters=classes, kernel_size=kernel_size,\n                                      strides=strides, padding='valid',\n                                      kernel_initializer='he_normal',\n                                      kernel_regularizer=l2(weight_decay),\n                                      use_bias=False,\n                                      name='upscore_{}'.format(block_name))(merge)\n        return upscore\n    return f\n\n\ndef vgg_upsampling(classes, target_shape=None, scale=1, weight_decay=0., block_name='featx'):\n    \"\"\"A VGG convolutional block with bilinear upsampling for decoding.\n\n    :param classes: Integer, number of classes\n    :param scale: Float, scale factor to the input feature, varing from 0 to 1\n    :param target_shape: 4D Tuples with targe_height, target_width as\n    the 2nd, 3rd elements if `channels_last` or as the 3rd, 4th elements if\n    `channels_first`.\n\n    >>> from keras_fcn.blocks import vgg_upsampling\n    >>> feat1, feat2, feat3 = feat_pyramid[:3]\n    >>> y = vgg_upsampling(classes=21, target_shape=(None, 14, 14, None),\n    >>>                    scale=1, block_name='feat1')(feat1, None)\n    >>> y = vgg_upsampling(classes=21, target_shape=(None, 28, 28, None),\n    >>>                    scale=1e-2, block_name='feat2')(feat2, y)\n    >>> y = vgg_upsampling(classes=21, target_shape=(None, 224, 224, None),\n    >>>                    scale=1e-4, block_name='feat3')(feat3, y)\n\n    \"\"\"\n    def f(x, y):\n        score = Conv2D(filters=classes, kernel_size=(1, 1),\n                       activation='linear',\n                       padding='valid',\n                       kernel_initializer='he_normal',\n                       kernel_regularizer=l2(weight_decay),\n                       name='score_{}'.format(block_name))(x)\n        if y is not None:\n            def scaling(xx, ss=1):\n                return xx * ss\n            scaled = Lambda(scaling, arguments={'ss': scale},\n                            name='scale_{}'.format(block_name))(score)\n            score = add([y, scaled])\n        upscore = BilinearUpSampling2D(\n            target_shape=target_shape,\n            name='upscore_{}'.format(block_name))(score)\n        return upscore\n    return f\n\n\ndef vgg_score(crop_offset='centered'):\n    \"\"\"A helper block to crop the decoded feature.\n\n    :param crop_offset: Tuple or \"centered\", the offset for cropping.\n    The default is \"centered\", which crop the center of the feature map.\n\n    >>> from keras_fcn.blocks import vgg_deconv\n    >>> score = vgg_score(crop_offset='centered')(image, upscore)\n\n    \"\"\"\n    def f(x, y):\n        score = CroppingLike2D(target_shape=K.int_shape(\n            x), offset=crop_offset, name='score')(y)\n        return score\n    return f\n",
			"file": "utils/NeMO_blocks.py",
			"file_size": 20804,
			"file_write_time": 131639227482017490,
			"settings":
			{
				"buffer_size": 20121,
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_encoders.py",
			"settings":
			{
				"buffer_size": 20953,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_decoders.py",
			"settings":
			{
				"buffer_size": 6245,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_models.py",
			"settings":
			{
				"buffer_size": 5927,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "AL_NeMO_hyperparamopt_VGG16FCN_64.py",
			"settings":
			{
				"buffer_size": 5401,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 392.0,
		"last_filter": "prv",
		"selected_items":
		[
			[
				"prv",
				"PackageResourceViewer: Open Resource"
			],
			[
				"install",
				"Package Control: Install Package"
			]
		],
		"width": 412.0
	},
	"console":
	{
		"height": 0.0,
		"history":
		[
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"file_history":
	[
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/preprocessing/image.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperparamopt_4AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_AlexNetHyperOpt_FullVisualization.ipynb",
		"/F/faceswap-GAN-master/FaceSwap_GAN_v2_train.py",
		"/F/faceswap-GAN-master/utils.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/tensorflow/contrib/framework/__init__.py",
		"/F/face-swap/model.py",
		"/F/face-swap/image_augmentation.py",
		"/F/face-swap/pixel_shuffler.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_FCN.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperparamopt_4AlexNetParallel.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Test_NeMO_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/init_args - VGG16FCN_Raster.yml",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/Test_NeMO_generator",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_callbacks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_FCNHyperOpt_FullVisualization.ipynb",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_hyperparamopt_4FCN.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_encoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_hyperparamopt_4AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/init_args - AlexNetParallel_Raster.yml",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_blocks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_blocks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_ResNet34.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/output/hyperas_NeMO_AlexNettest_log.csv",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/train2opt.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_AlexNetFullVisualize.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/TestCoralUtil.ipynb",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/init_args - AlexNet.yml",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/hyperas_example_with_fit_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_encoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperopt_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/.gitignore",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/temp_model.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/lstm.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/output/hyperas_AlexNet_hyperopttest_log.csv",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/globalvars.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Untitled.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/temp_model.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/hyperopt_example.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/hyperopt/pyll/base.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/loadcoraldata_utils.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/alignUAVtoSat/cvk2.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_backend.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/alignUAVtoSat/Match_Images.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/train.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/score.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMOgenerator.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/tests/test_models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_NeMOgenerator.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/test_voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_decoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/loadcoraldata_utils.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_decoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_losses.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/common.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/backend/tensorflow_backend.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/losses.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/callbacks.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/backend/common.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/encoders.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/__init__.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_losses.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/callbacks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/losses.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/blocks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_NeMOgenerator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMOlayers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/encoders.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/setup.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_sample.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_NeMO_voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/models.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/__init__.py",
		"/C/Users/Rechant/Documents/MachineLearning/mnist_mlp.py",
		"/C/Users/Rechant/AppData/Roaming/Sublime Text 3/Packages/Color Scheme - Default/Monokai.tmTheme",
		"/C/Users/Rechant/AppData/Roaming/Sublime Text 3/Packages/Theme - Default/Default.sublime-theme"
	],
	"find":
	{
		"height": 23.0
	},
	"find_in_files":
	{
		"height": 104.0,
		"where_history":
		[
			""
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"lambda",
			"yield",
			"lrD",
			"pool_concat",
			"scaling",
			"labelkey",
			"summary",
			"img_to_array",
			"classifyback",
			"data_format",
			"_rescale",
			"uint8",
			"str(lr)",
			"optModel",
			"input_shape",
			"numpy",
			"except",
			"HEAD",
			"classes",
			"n",
			"space",
			"optModel",
			"space",
			"numpy",
			"trials",
			"batch_size",
			"iterator",
			"img_to_array",
			"temp.tif",
			"directoryIterator",
			"flow_from_direc",
			"flow_from",
			"fname",
			"index_array",
			"self.index_generator",
			"uint",
			"f.write",
			"get_file",
			"gray",
			"counter",
			"get_file",
			"load_seg",
			"datagen",
			"image_resample",
			"rescale",
			"offset",
			"index_generator",
			"IndexIterator",
			"IndexGenerator",
			"load_seg",
			"keras_fcn",
			"keras_func",
			"NeMO",
			"increment_var",
			"FCN",
			"index_generator",
			"IndexI",
			"indexiterator"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"np"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "utils/loadcoraldata_utils.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 27184,
						"regions":
						{
						},
						"selection":
						[
							[
								22487,
								22487
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 6738.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "utils/NeMO_generator.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 26758,
						"regions":
						{
						},
						"selection":
						[
							[
								16776,
								16776
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 5026.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "utils/NeMO_layers.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5869,
						"regions":
						{
						},
						"selection":
						[
							[
								0,
								0
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 385.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "utils/NeMO_blocks.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 20121,
						"regions":
						{
						},
						"selection":
						[
							[
								1782,
								1863
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 494.0,
						"zoom_level": 1.0
					},
					"stack_index": 7,
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "utils/NeMO_encoders.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 20953,
						"regions":
						{
						},
						"selection":
						[
							[
								16861,
								16861
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 5000.0,
						"zoom_level": 1.0
					},
					"stack_index": 6,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "utils/NeMO_decoders.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 6245,
						"regions":
						{
						},
						"selection":
						[
							[
								5454,
								5454
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 1429.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 6,
					"file": "utils/NeMO_models.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5927,
						"regions":
						{
						},
						"selection":
						[
							[
								845,
								845
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 270.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 7,
					"file": "AL_NeMO_hyperparamopt_VGG16FCN_64.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5401,
						"regions":
						{
						},
						"selection":
						[
							[
								2131,
								2131
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 752.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 23.0
	},
	"input":
	{
		"height": 0.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.find_results":
	{
		"height": 0.0
	},
	"pinned_build_system": "",
	"project": "NeMO-Net.sublime-project",
	"replace":
	{
		"height": 42.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 150.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
