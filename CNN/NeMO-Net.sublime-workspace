{
	"auto_complete":
	{
		"selected_items":
		[
		]
	},
	"buffers":
	[
		{
			"file": "utils/NeMO_generator.py",
			"settings":
			{
				"buffer_size": 27441,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_layers.py",
			"settings":
			{
				"buffer_size": 5869,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_blocks.py",
			"settings":
			{
				"buffer_size": 21432,
				"line_ending": "Windows"
			}
		},
		{
			"contents": "from __future__ import (\n    absolute_import,\n    unicode_literals\n)\nimport numpy as np\nimport copy\nimport keras\nimport keras.backend as K\n\n#from keras.models import Model\nfrom keras.engine.training import Model\nfrom keras.utils.data_utils import get_file\nfrom keras.utils import layer_utils\n\nfrom keras.layers import Cropping2D, Concatenate, Add\nfrom NeMO_blocks import (\n    alex_conv,\n    alex_fc,\n    parallel_conv,\n    vgg_convblock,\n    vgg_fcblock,\n    pool_concat,\n    res_initialconv,\n    res_basicconv,\n    res_megaconv,\n    res_1b1conv,\n    res_fc,\n    vgg_conv,\n    vgg_fc\n)\nfrom NeMO_backend import load_weights\n\nfrom hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n\n\nclass Encoder(Model):\n    \"\"\"Encoder for Fully Convolutional Networks.\n    :param inputs: 4D Tensor, the input tensor\n    :param blocks: 1D array, list of functional convolutional blocks\n\n    :return A Keras Model with outputs including the output of\n    each block except the final conv block (using the encoder's top instead)\n\n    >>> from keras.layers import Input\n    >>> from keras_fcn.encoders import Encoder\n    >>> from keras_fcn.blocks import (vgg_conv, vgg_fc)\n    >>> inputs = Input(shape=(224, 224, 3))\n    >>> blocks = [vgg_conv(64, 2, 'block1'),\n    >>>           vgg_conv(128, 2, 'block2'),\n    >>>           vgg_conv(256, 3, 'block3'),\n    >>>           vgg_conv(512, 3, 'block4'),\n    >>>           vgg_conv(512, 3, 'block5'),\n    >>>           vgg_fc(4096)]\n    >>> encoder = Encoder(inputs, blocks, weights='imagenet',\n    >>>                   trainable=True)\n    >>> feat_pyramid = encoder.outputs   # A feature pyramid with 5 scales\n\n    \"\"\"\n\n    def __init__(self, inputs, blocks, weights=None,\n                 trainable=True, name='encoder'):\n        inverse_pyramid = []\n\n        # convolutional block\n        conv_blocks = blocks[:-1]\n        for i, block in enumerate(conv_blocks):\n            if i == 0:\n                x = block(inputs)\n                inverse_pyramid.append(x)\n            elif i < len(conv_blocks) - 1:\n                x = block(x)\n                inverse_pyramid.append(x)\n            else:\n                x = block(x)\n\n        # fully convolutional block\n        fc_block = blocks[-1]\n        y = fc_block(x)\n        inverse_pyramid.append(y)\n\n        outputs = list(reversed(inverse_pyramid))\n\n        super(Encoder, self).__init__(\n            inputs=inputs, outputs=outputs)\n\n        # load pre-trained weights\n        if weights is not None:\n            weights_path = get_file(\n                '{}_weights_tf_dim_ordering_tf_kernels.h5'.format(name),\n                weights,\n                cache_subdir='models')\n            layer_names = load_weights(self, weights_path)\n            if K.image_data_format() == 'channels_first':\n                layer_utils.convert_all_kernels_in_model(self)\n\n        # Freezing basenet weights\n        if trainable is False:\n            for layer in self.layers:\n                if layer.name in layer_names:\n                    layer.trainable = False\n\n\nclass Res_Encoder(Model):\n    \"\"\"Same as Encoder, but does not get rid of any output blocks\n    :param inputs: 4D Tensor, the input tensor\n    :param blocks: 1D array, list of functional convolutional blocks\n\n    :return A Keras Model with outputs\n    \"\"\"\n\n    # inputs: normal input\n    # blocks: blocks that make up the encoder\n    # crop_shapes: list of tuples indicating shapes to be cropped out of the center of inputs (e.g. [(5,5),(10,10)])\n    # weights: weights to be loaded (if any)\n    # traininable: Trainable layers\n    # name: Name of encoder\n    def __init__(self, inputs, blocks, weights=None, trainable=True, name='encoder'):\n        inverse_pyramid = []\n\n        # split_inputs = None \n        # if crop_shapes is not None:             # used for multi-input models\n        #     split_inputs = []\n        #     for shape in crop_shapes:\n        #         crop_len = (int(inputs.shape[1])-shape[0])/2\n        #         if (int(inputs.shape[1]) - shape[0])%2 == 0:\n        #             crop_len = int(crop_len)\n        #             split_inputs.append(Cropping2D(cropping=((crop_len,crop_len), (crop_len,crop_len)))(inputs))\n        #         else:\n        #             crop_len_lo = int(np.trunc(crop_len))\n        #             crop_len_hi = int(np.ceil(crop_len))\n        #             split_inputs.append(Cropping2D(cropping=((crop_len_lo,crop_len_hi), (crop_len_lo,crop_len_hi)))(inputs))\n\n        # all parallel blocks\n        if type(inputs) is list:\n            inputs_copy = [np.copy(inp) for inp in inputs]\n        else:\n            inputs_copy = inputs\n\n        for i, block in enumerate(blocks):\n            if i == 0:\n                x = block(inputs_copy)\n            else:\n                x = block(x)\n\n            if type(x) is list:\n                inverse_pyramid.append(list(x))\n                # print([xi.shape for xi in x])\n            else:\n                inverse_pyramid.append(x)\n                # print(x.shape)\n\n        pyramid = reversed(inverse_pyramid)\n        outputs = []\n        for item in pyramid:\n            if type(item) is list:\n                for miniitem in item:\n                    outputs.append(miniitem)\n            else:\n                outputs.append(item)\n        # outputs = list(reversed(inverse_pyramid))\n\n        super(Res_Encoder, self).__init__(inputs=inputs, outputs=outputs)\n        print(self.summary())\n\n        # load pre-trained weights\n        if weights is not None:\n            weights_path = get_file(\n                '{}_weights_tf_dim_ordering_tf_kernels.h5'.format(name),\n                weights,\n                cache_subdir='models')\n            layer_names = load_weights(self, weights_path)\n            if K.image_data_format() == 'channels_first':\n                layer_utils.convert_all_kernels_in_model(self)\n\n        # Freezing basenet weights\n        if trainable is False:\n            for layer in self.layers:\n                if layer.name in layer_names:\n                    layer.trainable = False\n\nclass Alex_Encoder(Res_Encoder):\n    def __init__(self, inputs, classes, weight_decay=0., weights=None, trainable=True):\n        # filters = [64, 128, 256, 384, 512]\n        # conv_size = [(7,7),(5,5),(3,3),(3,3),(3,3)]\n        # pool_size = [(2,2),(2,2),(1,1),(1,1),(2,2)]\n        # pool_stride = [(2,2),(2,2),(1,1),(1,1),(2,2)]\n        # pool_bool = [True, True, False, False, True]\n        # pad_bool = [False, False, True, True, True]\n        # batchnorm_bool = [True, True, False, False, False]\n        filters = [64, 128]\n        conv_size = [(7,7),(5,5)]\n        pool_size = [(2,2),(2,2)]\n        pool_stride = [(2,2),(2,2)]\n        pool_bool = [True, True]\n        pad_bool = [False, False]\n        batchnorm_bool = [True, True]\n\n        full_filters = [256]\n        drop_bool = [True]\n        drop_val = [0.5]\n        \n        blocks = []\n        for i in range(len(filters)):\n            block_name = 'alexblock{}'.format(i + 1)\n            block = alex_conv(filters[i], conv_size[i], pad_bool=pad_bool[i], pool_bool=pool_bool[i], batchnorm_bool=batchnorm_bool[i], \n                pool_size=pool_size[i], pool_strides=pool_stride[i], weight_decay=weight_decay, block_name=block_name)\n            blocks.append(block)\n\n        for i in range(len(full_filters)):\n            block_name='alexfc{}'.format(i + 1)\n            if i==0:\n                block = alex_fc(full_filters[i], flatten_bool=True, dropout_bool=drop_bool[i], dropout=drop_val[i], weight_decay=weight_decay, \n                    block_name=block_name)\n            else:\n                block = alex_fc(full_filters[i], flatten_bool=False, dropout_bool=drop_bool[i], dropout=drop_val[i], weight_decay=weight_decay, \n                    block_name=block_name)\n            blocks.append(block)\n\n        super(Alex_Encoder, self).__init__(inputs=inputs, blocks=blocks, weights=weights, trainable = trainable)\n\ndef load_specific_param(num_layers, default_conv_params, conv_params, specific_param, layer_str=\"convolutional\"):\n    default_param = default_conv_params[specific_param]\n    try:\n        param = conv_params[specific_param]\n        if len(param) != num_layers:\n            print(\"Found {} {} layers but {} {}, will only replace initial {} {}...\".format(num_layers, layer_str, len(param), specific_param, len(param), specific_param))\n            for i in range(len(param), num_layers):\n                param.append(default_param[i])\n        print(\"{}: {}\".format(specific_param, param[:num_layers]))\n    except:\n        print(\"{} not found, reverting to default: {}\".format(specific_param,default_param[:num_layers]))\n        param = default_param\n\n    return param\n\ndef load_conv_params(conv_layers, full_layers, default_conv_params, conv_params):\n    print(\"---------------------------------------------------------\")\n    print(\"ENCODER CONVOLUTIONAL PARAMETERS:\")\n\n    filters = load_specific_param(conv_layers, default_conv_params, conv_params, \"filters\")\n    conv_size = load_specific_param(conv_layers, default_conv_params, conv_params, \"conv_size\")\n    conv_strides = load_specific_param(conv_layers, default_conv_params, conv_params, \"conv_strides\")\n    padding = load_specific_param(conv_layers, default_conv_params, conv_params, \"padding\")\n    dilation_rate = load_specific_param(conv_layers, default_conv_params, conv_params, \"dilation_rate\")\n    pool_size = load_specific_param(conv_layers, default_conv_params, conv_params, \"pool_size\")\n    pool_strides = load_specific_param(conv_layers, default_conv_params, conv_params, \"pool_strides\")\n    pad_size = load_specific_param(conv_layers, default_conv_params, conv_params, \"pad_size\")\n    layercombo = load_specific_param(conv_layers, default_conv_params, conv_params, \"layercombo\")\n    # batchnorm_pos = load_specific_param(conv_layers, default_conv_params, conv_params, \"batchnorm_pos\") #old version has batchnorm_bool\n    full_filters = load_specific_param(full_layers, default_conv_params, conv_params, \"full_filters\", layer_str=\"fully connected\")\n    dropout = load_specific_param(full_layers, default_conv_params, conv_params, \"dropout\", layer_str=\"fully connected\")\n\n    return filters, conv_size, conv_strides, padding, dilation_rate, pool_size, pool_strides, pad_size, layercombo, full_filters, dropout\n\n\nclass Alex_Hyperopt_Encoder(Res_Encoder):\n    def __init__(self, inputs, classes, weight_decay=0., weights=None, trainable=True, conv_layers=5, full_layers=2, conv_params=None):\n\n        default_conv_params = {\"filters\": [96,256,384,384,256],\n            \"conv_size\": [(7,7),(5,5),(3,3),(3,3),(3,3)],\n            \"conv_strides\": [(1,1),(1,1),(1,1),(1,1),(1,1)],\n            \"padding\": ['valid','valid','valid','valid','valid'],\n            \"dilation_rate\": [(1,1),(1,1),(1,1),(1,1),(1,1)],\n            \"pool_size\": [(2,2),(2,2),(1,1),(1,1),(2,2)],\n            \"pad_size\": [(0,0),(0,0),(0,0),(0,0),(0,0)],\n            \"layercombo\": [\"capb\",\"capb\",\"capb\",\"capb\",\"capb\"],\n            \"full_filters\": [4096,4096],\n            \"dropout\": [0.5,0.5]}\n        filters, conv_size, padding, dilation_rate, pool_size, pad_size, layercombo, full_filters, dropout = \\\n            load_conv_params(conv_layers, full_layers, default_conv_params, conv_params)\n\n        # actual start of CNN\n        blocks = []\n        for i in range(conv_layers):\n            block_name = 'alexblock{}'.format(i + 1)\n            block = alex_conv(filters[i], conv_size[i], conv_strides=(1,1), padding=padding[i], pad_bool=True, pad_size=pad_size[i], pool_size=pool_size[i],\n                pool_strides=pool_size[i], dilation_rate=dilation_rate[i], layercombo=layercombo[i], weight_decay=weight_decay, block_name=block_name)\n            blocks.append(block)\n\n        for i in range(full_layers):\n            block_name='alexfc{}'.format(i + 1)\n            if i==0:\n                block = alex_fc(full_filters[i], flatten_bool=True, dropout_bool=True, dropout=dropout[i], weight_decay=weight_decay, block_name=block_name)\n            else:\n                block = alex_fc(full_filters[i], flatten_bool=False, dropout_bool=True, dropout=dropout[i], weight_decay=weight_decay, block_name=block_name)\n            blocks.append(block)\n\n        super(Alex_Hyperopt_Encoder, self).__init__(inputs=inputs, blocks=blocks, weights=weights, trainable = trainable)\n\nclass Alex_Parallel_Hyperopt_Encoder(Res_Encoder):\n    def __init__(self, inputs, classes, parallel_layers=4, combine_method='concat', conv_params=None, weight_decay=0., weights=None, trainable=True):\n\n        # double brackets to signify all parallel filters follow same parameters\n        default_conv_params = {\"filters\": [[1024,1024,classes]],\n            \"conv_size\": [[(3,3),(1,1),(1,1)]],\n            \"conv_strides\":  [[(3,3),(1,1),(1,1)]],\n            \"padding\": ['same','same','same','same'],\n            \"dilation_rate\": [[(6,6),(1,1),(1,1)], [(12,12),(1,1),(1,1)], [(18,18),(1,1),(1,1)], [(24,24),(1,1),(1,1)]],\n            \"pool_size\": [[(2,2),(2,2),(2,2)]],\n            \"pool_strides\": [[(2,2),(2,2),(2,2)]],\n            \"pad_size\": [(6,6), (12,12), (18,18), (24,24)],\n            \"layercombo\": [\"zcadcadc\",\"zcadcadc\",\"zcadcadc\",\"zcadcadc\"],\n            \"full_filters\": [4096,2048],\n            \"dropout\": [0.5,0.5]}\n        filters = conv_params[\"filters\"]\n        conv_size = conv_params[\"conv_size\"]\n        conv_strides = conv_params[\"conv_strides\"]\n        padding = conv_params[\"padding\"]\n        dilation_rate = conv_params[\"dilation_rate\"]\n        pool_size = conv_params[\"pool_size\"]\n        pool_strides = conv_params[\"pool_strides\"]\n        pad_size = conv_params[\"pad_size\"]\n        layercombo = conv_params[\"layercombo\"]\n\n        # f = lambda input,c_count: input[0] if len(input)==1 else input[c_count]\n        # actual start of CNN\n        blocks = []\n        block_name = 'parallel_block'\n        block = parallel_conv(filters, conv_size, conv_strides=conv_strides, padding=padding, pad_bool=True, pad_size=pad_size, \n            pool_size=pool_size, pool_strides=pool_strides, dilation_rate=dilation_rate, dropout=[0.5], layercombo=layercombo,\n            weight_decay=weight_decay, block_name=block_name)\n        blocks.append(block)\n\n        if combine_method == \"concat\":\n            block = Concatenate(axis=-1)\n            blocks.append(block)\n        elif combine_method == \"add\":\n            block = Add()\n            blocks.append(block)\n\n        super(Alex_Parallel_Hyperopt_Encoder, self).__init__(inputs=inputs, blocks=blocks, weights=weights, trainable = trainable)\n\nclass VGG_Hyperopt_Encoder(Res_Encoder):\n    def __init__(self, inputs, classes, weight_decay=0., weights=None, trainable=True, \n        conv_layers=5, full_layers=2, conv_params=None):\n\n        default_conv_params = {\"filters\": [64,128,256,512,512],\n            \"conv_size\": [(3,3),(3,3),(3,3),(3,3),(3,3)],\n            \"conv_strides\": [(1,1),(1,1),(1,1),(1,1),(1,1)],\n            \"padding\": ['same','same','same','same','same'],\n            \"dilation_rate\": [(1,1),(1,1),(1,1),(1,1),(1,1)],\n            \"pool_size\": [(2,2),(2,2),(2,2),(2,2),(2,2)],\n            \"pool_strides\": [(2,2),(2,2),(1,1),(1,1),(1,1)],\n            \"pad_size\": [(0,0),(0,0),(0,0),(0,0),(0,0)],\n            \"layercombo\": [\"cacapb\",\"cacapba\",\"cacacapb\",\"cacacapb\",\"cacacapb\"],\n            \"full_filters\": [2048,2048],\n            \"dropout\": [0.5,0.5]}\n        filters, conv_size, conv_strides, padding, dilation_rate, pool_size, pool_strides, pad_size, layercombo, full_filters, dropout = \\\n            load_conv_params(conv_layers, full_layers, default_conv_params, conv_params)\n\n        # actual start of CNN\n        blocks = []\n        for i in range(conv_layers):\n            block_name = 'vgg_convblock{}'.format(i + 1)\n            block = alex_conv(filters[i], conv_size[i], conv_strides=conv_strides[i], padding=padding[i], pad_bool=False, pad_size=pad_size[i], pool_size=pool_size[i],\n                pool_strides=pool_strides[i], dilation_rate=dilation_rate[i], layercombo=layercombo[i], weight_decay=weight_decay, block_name=block_name)\n            blocks.append(block)\n\n        if full_layers > 0:\n            block_name = 'vgg_fcblock'\n            block = vgg_fcblock(full_filters, full_layers, dropout_bool=True, dropout=dropout, weight_decay=weight_decay, block_name=block_name)\n            blocks.append(block)\n\n        super(VGG_Hyperopt_Encoder, self).__init__(inputs=inputs, blocks=blocks, weights=weights, trainable = trainable)\n\n\nclass Res34_Encoder(Res_Encoder):\n    def __init__(self, inputs, classes, weight_decay=0., weights=None, trainable=True, fcflag = False):\n        weights = None\n        filters = [64, 128, 256, 512]\n        convs = [2,2,2,2]\n        reps = [3,4,6,3]\n        blocks = []\n\n        init_block = res_initialconv(filters=64, weight_decay = weight_decay)\n        blocks.append(init_block)\n\n        for i, (fltr, conv) in enumerate(zip(filters, convs)):\n            block_name = 'megablock{}'.format(i + 1)\n            if i==0:\n                block = res_megaconv(fltr, conv, reps[i], init_strides=(1,1), weight_decay=weight_decay, block_name=block_name)\n            else:\n                block = res_megaconv(fltr, conv, reps[i], init_strides=(2,2), weight_decay=weight_decay, block_name=block_name)\n            blocks.append(block)\n\n        if fcflag:\n            fc_block = res_fc(classes=classes, weight_decay=weight_decay)\n        else:\n            fc_block = res_1b1conv(filters=512, convs=1, weight_decay = weight_decay)\n        blocks.append(fc_block)\n\n        super(Res34_Encoder, self).__init__(inputs=inputs, blocks=blocks, weights=weights, trainable=trainable)\n\nclass VGGEncoder(Encoder):\n    \"\"\"VGG VGGEncoder.\n\n    :param inputs: 4D Tensor, the input tensor\n    :param filters: 1D array, number of filters per block\n    :param convs: 1D array, number of convolutional layers per block, with\n    length the same as `filters`.\n\n    :return A Keras Model with outputs including the output of\n    each block except `pool5` (using drop7 from `pool5` instead)\n\n    >>> from keras_fcn.encoders import VGGEncoder\n    >>> from keras.layers import Input\n    >>> x = Input(shape=(224, 224, 3))\n    >>> encoder = VGGEncoder(Input(x),\n    >>>                  filters=[64, 128, 256, 512, 512],\n    >>>                  convs=[2, 2, 3, 3, 3])\n    >>> feat_pyramid = encoder.outputs\n\n    \"\"\"\n\n    def __init__(self, inputs, filters, convs, weight_decay=0.,\n            weights=None, trainable=True):\n        blocks = []\n\n        # Convolutional blocks\n        for i, (fltr, conv) in enumerate(zip(filters, convs)):\n            block_name = 'block{}'.format(i + 1)\n            block = vgg_conv(filters=fltr, convs=conv, padding=False,\n                             weight_decay=weight_decay,\n                             block_name=block_name)\n            blocks.append(block)\n\n        # Fully Convolutional block\n        fc_block = vgg_fc(filters=1024, weight_decay=weight_decay)\n        # fc_block = vgg_fc(filters=4096, weight_decay=weight_decay)\n\n        blocks.append(fc_block)\n\n        super(VGGEncoder, self).__init__(inputs=inputs, blocks=blocks,\n                                         weights=weights, trainable=trainable)\n\n\nclass VGG16(VGGEncoder):\n    \"\"\"A VGG16 feature encoder.\n\n    >>> from keras_fcn.encoders import VGG16\n    >>> from keras.layers import Input\n    >>> x = Input(shape=(224, 224, 3))\n    >>> encoder = VGG16(x)\n    >>> feat_pyramid = encoder.outputs\n\n    \"\"\"\n\n    def __init__(self, inputs, weight_decay=0.,\n            weights='imagenet', trainable=True):\n        if weights == 'imagenet':\n            weights = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        else:\n            weights = None\n\n        super(VGG16, self).__init__(inputs,\n                                    filters=[64, 128, 196, 256, 384],\n                                    convs=[2, 2, 3, 3, 3],\n                                    weight_decay=weight_decay,\n                                    weights=weights,\n                                    trainable=trainable)\n\n        # super(VGG16, self).__init__(inputs,\n        #                             filters=[64, 128, 256, 512, 512],\n        #                             convs=[2, 2, 3, 3, 3],\n        #                             weight_decay=weight_decay,\n        #                             weights=weights,\n        #                             trainable=trainable)\n\n\nclass VGG19(VGGEncoder):\n    \"\"\"VGG19 net.\n\n    >>> from keras_fcn.encoders import VGG19\n    >>> from keras.layers import Input\n    >>> x = Input(shape=(224, 224, 3))\n    >>> encoder = VGG19(x)\n    >>> feat_pyramids = encoder.outputs\n\n    \"\"\"\n\n    def __init__(self, inputs, weight_decay=0.,\n            weights='imagenet', trainable=True):\n        if weights == 'imagenet':\n            weights = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        else:\n            weights = None\n\n        super(VGG19, self).__init__(inputs,\n                                    filters=[64, 128, 256, 512, 512],\n                                    convs=[2, 2, 4, 4, 4],\n                                    weight_decay=weight_decay,\n                                    weights=weights,\n                                    trainable=trainable)\n",
			"file": "utils/NeMO_encoders.py",
			"file_size": 21854,
			"file_write_time": 131643242833031458,
			"settings":
			{
				"buffer_size": 21361,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_decoders.py",
			"settings":
			{
				"buffer_size": 6245,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/NeMO_models.py",
			"settings":
			{
				"buffer_size": 7823,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"contents": "import os\nimport yaml\nimport datetime\nimport numpy as np\nimport keras\nimport keras.backend as K\nimport tensorflow as tf\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n\nglobal _SESSION\nconfig = tf.ConfigProto(allow_soft_placement=True)\nconfig.gpu_options.allow_growth = True\n_SESSION = tf.Session(config=config)\nK.set_session(_SESSION)\n\nimport sys\nsys.path.append(\"./utils/\") # Adds higher directory to python modules path.\nimport loadcoraldata_utils as coralutils\nfrom NeMO_models import VGG16_DeepLabV2\nfrom NeMO_generator import NeMOImageGenerator, ImageSetLoader\nfrom NeMO_backend import get_model_memory_usage\nfrom keras.callbacks import (\n    ReduceLROnPlateau,\n    CSVLogger,\n    EarlyStopping,\n    ModelCheckpoint,\n    TerminateOnNaN)\nfrom NeMO_callbacks import CheckNumericsOps, WeightsSaver\n\nimage_size = 256\nbatch_size = 6\nmodel_name = 'VGG16DeepLab_Raster256'\n\nimgpath = '../Images/BTPB-WV2-2012-15-8Band-mosaic-GeoTiff-Sample-AOI/BTPB-WV2-2012-15-8Band-mosaic-GeoTiff-Sample-AOI.tif'\ntfwpath = '../Images/BTPB-WV2-2012-15-8Band-mosaic-GeoTiff-Sample-AOI/BTPB-WV2-2012-15-8Band-mosaic-GeoTiff-Sample-AOI.tfw'\ntruthpath = '../Images/BIOT-PerosBanhos-sample-habitat-map/BIOT-PerosBanhos-sample-habitat-map.shp'\nPerosBanhos = coralutils.CoralData(imgpath, Truthpath=truthpath, load_type=\"raster\", tfwpath=tfwpath)\n# PerosBanhos.load_PB_consolidated_classes()\n\nlabelkey = PerosBanhos.class_labels\nnum_classes = len(labelkey)\n# labelkey = PerosBanhos.consol_labels\n# num_classes = len(PerosBanhos.PB_consolidated_classes)\n\nwith open(\"init_args - VGG16DeepLab_Raster256.yml\", 'r') as stream:\n    try:\n        init_args = yaml.load(stream)\n    except yaml.YAMLError as exc:\n        print(exc)\n\ntrain_loader = ImageSetLoader(**init_args['image_set_loader']['train'])\nval_loader = ImageSetLoader(**init_args['image_set_loader']['val'])\n\nif train_loader.color_mode == 'rgb':\n    num_channels = 3\nelif train_loader.color_mode == '8channel':\n    num_channels = 8\n\ny = train_loader.target_size[1]\nx = train_loader.target_size[0]\npixel_mean =1023.5*np.ones(num_channels)\npixel_std = 1023.5*np.ones(num_channels)\n\ncheckpointer = ModelCheckpoint(filepath=\"./tmp/\" + model_name + \".h5\", verbose=1, monitor='val_acc', mode='max', save_best_only=True)\nlr_reducer = ReduceLROnPlateau(monitor='val_loss',\n                               factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=10, min_lr=1e-12)\nearly_stopper = EarlyStopping(monitor='val_loss',\n                              min_delta=0.001,\n                              patience=30)\nnan_terminator = TerminateOnNaN()\nSaveWeights = WeightsSaver(filepath='./weights/', model_name=model_name, N=10)\n#csv_logger = CSVLogger('output/tmp_fcn_vgg16.csv')\n    #'output/{}_fcn_vgg16.csv'.format(datetime.datetime.now().isoformat()))\n\n#check_num = CheckNumericsOps(validation_data=[np.random.random((1, 224, 224, 3)), 1],\n#                             histogram_freq=100)\n\n# log history during model fit\ncsv_logger = CSVLogger('output/log.csv', append=True, separator=';')\n\ndatagen = NeMOImageGenerator(image_shape=[y, x, num_channels],\n                                    image_resample=True,\n                                    pixelwise_center=True,\n                                    pixel_mean=pixel_mean,\n                                    pixelwise_std_normalization=True,\n                                    pixel_std=pixel_std)\ntrain_generator = datagen.flow_from_NeMOdirectory(train_loader.image_dir,\n    FCN_directory=train_loader.label_dir,\n    target_size=(x,y),\n    color_mode=train_loader.color_mode,\n    classes = labelkey,\n    class_weights = PerosBanhos.class_weights,\n    class_mode = 'categorical',\n    batch_size = batch_size,\n    shuffle=True)\n\nvalidation_generator = datagen.flow_from_NeMOdirectory(val_loader.image_dir,\n    FCN_directory=val_loader.label_dir,\n    target_size=(x,y),\n    color_mode=val_loader.color_mode,\n    classes = labelkey,\n    class_weights = PerosBanhos.class_weights,\n    class_mode = 'categorical',\n    batch_size = batch_size,\n    shuffle=True)\n\nconv_layers = 5\nfull_layers = 0\n\nconv_params = {\"filters\": [64,128,256,512,512],\n    \"conv_size\": [(3,3),(3,3),(3,3),(3,3),(3,3)],\n    \"conv_strides\": [(1,1),(1,1),(1,1),(1,1),(1,1)],\n    \"padding\": ['same','same','same','same','same'],\n    \"dilation_rate\": [(1,1),(1,1),(1,1),(1,1),(2,2)],\n    \"pool_size\": [(2,2),(2,2),(2,2),(3,3),(3,3)],\n    \"pool_strides\": [(2,2),(2,2),(2,2),(1,1),(1,1)],\n    \"pad_size\": [(0,0),(0,0),(1,1),(1,1),(1,1)],\n    \"layercombo\": [\"cacapb\",\"cacapb\",\"cacacapb\",\"cacacazpb\",\"cacacazp\"],\n    \"full_filters\": [1024,1024],\n    \"dropout\": [0,0]}\n\nparallelconv_params = {\"filters\": [[1024,1024,num_classes]],\n    \"conv_size\": [[(3,3),(1,1),(1,1)]],\n    \"conv_strides\":  [[(1,1),(1,1),(1,1)]],\n    \"padding\": ['valid','valid','valid','valid'],\n    \"dilation_rate\": [[(6,6),(1,1),(1,1)], [(12,12),(1,1),(1,1)], [(18,18),(1,1),(1,1)], [(24,24),(1,1),(1,1)]],\n    \"pool_size\": [[(2,2),(2,2),(2,2)]], #doesn't matter\n    \"pool_strides\": [[(2,2),(2,2),(2,2)]], #doesn't matter\n    \"pad_size\": [[(6,6),(0,0),(0,0)], [(12,12),(0,0),(0,0)], [(18,18),(0,0),(0,0)], [(24,24),(0,0),(0,0)]],\n    \"layercombo\": [\"zcadcadc\",\"zcadcadc\",\"zcadcadc\",\"zcadcadc\"],\n    \"full_filters\": [4096,2048],\n    \"dropout\": [0.5,0.5]}\n\nVGG16_DeepLab = VGG16_DeepLabV2(input_shape=(y, x, num_channels), classes=num_classes, weight_decay=3e-3, batch_size=batch_size, \n                weights=None, trainable_encoder=True, conv_layers=5, full_layers=0, conv_params=conv_params, parallel_layers=4, parallelconv_params=parallelconv_params)\noptimizer = keras.optimizers.Adam(1e-4)\n\nVGG16_DeepLab.summary()\nVGG16_DeepLab.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n\n# print(\"Memory required (GB): \", get_model_memory_usage(batch_size, VGG16_DeepLab))\n\nVGG16_DeepLab.fit_generator(train_generator,\n    steps_per_epoch=4000,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=100,\n    verbose=1,\n    callbacks=[lr_reducer, early_stopper, nan_terminator, checkpointer])",
			"file": "AL_NeMO_hyperparamopt_VGG16DeepLabV2_256.py",
			"file_size": 6289,
			"file_write_time": 131644429102385120,
			"settings":
			{
				"buffer_size": 6138,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		},
		{
			"file": "utils/loadcoraldata_utils.py",
			"settings":
			{
				"buffer_size": 28256,
				"encoding": "UTF-8",
				"line_ending": "Windows"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 392.0,
		"last_filter": "prv",
		"selected_items":
		[
			[
				"prv",
				"PackageResourceViewer: Open Resource"
			],
			[
				"install",
				"Package Control: Install Package"
			]
		],
		"width": 412.0
	},
	"console":
	{
		"height": 0.0,
		"history":
		[
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"file_history":
	[
		"/C/Users/Rechant/Documents/pydensecrf-master/examples/inference.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/pydensecrf-1.0rc2-py3.6-win-amd64.egg/pydensecrf/utils.py",
		"/C/Users/Rechant/Documents/pydensecrf-master/tests/test_utils.py",
		"/C/Users/Rechant/Documents/pydensecrf-master/pydensecrf/utils.py",
		"/C/Users/Rechant/Documents/pydensecrf-master/pydensecrf/test_eigen.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/pydensecrf-1.0rc2-py3.6-win-amd64.egg/pydensecrf/eigen.cp36-win_amd64.pyd",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/pydensecrf-1.0rc2-py3.6-win-amd64.egg/pydensecrf/densecrf.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/pydensecrf-1.0rc2-py3.6-win-amd64.egg/pydensecrf/eigen.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_functional_encoders.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/engine/training.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/utils/generic_utils.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/engine/topology.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Test_CustomModelLoad.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/layers/__init__.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/loadcoraldata_utils.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_blocks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperparamopt_VGG16FCN_64.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/keras/preprocessing/image.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperparamopt_4AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_AlexNetHyperOpt_FullVisualization.ipynb",
		"/F/faceswap-GAN-master/FaceSwap_GAN_v2_train.py",
		"/F/faceswap-GAN-master/utils.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/tensorflow/contrib/framework/__init__.py",
		"/F/face-swap/model.py",
		"/F/face-swap/image_augmentation.py",
		"/F/face-swap/pixel_shuffler.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_FCN.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperparamopt_4AlexNetParallel.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Test_NeMO_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/init_args - VGG16FCN_Raster.yml",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/Test_NeMO_generator",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_callbacks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_FCNHyperOpt_FullVisualization.ipynb",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_hyperparamopt_4FCN.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_encoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_hyperparamopt_4AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/init_args - AlexNetParallel_Raster.yml",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_blocks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/NeMO_ResNet34.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/output/hyperas_NeMO_AlexNettest_log.csv",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/train2opt.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Keras_AlexNetFullVisualize.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/TestCoralUtil.ipynb",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/init_args - AlexNet.yml",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/hyperas_example_with_fit_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_encoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/AL_NeMO_hyperopt_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/.gitignore",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/temp_model.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/lstm.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/output/hyperas_AlexNet_hyperopttest_log.csv",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/globalvars.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/Untitled.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/temp_model.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/hyperparamopt_utils/hyperopt_example.py",
		"/C/Users/Rechant/AppData/Local/Programs/Python/Python36/Lib/site-packages/hyperopt/pyll/base.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_AlexNet.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/alignUAVtoSat/cvk2.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_backend.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/alignUAVtoSat/Match_Images.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/train.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/score.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMOgenerator.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/tests/test_models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_NeMOgenerator.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/test_voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_decoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/loadcoraldata_utils.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_decoders.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_losses.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/common.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/backend/tensorflow_backend.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/losses.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/callbacks.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/backend/common.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/encoders.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/__init__.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_losses.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/tests/test_layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/callbacks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/losses.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/models.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/blocks.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_NeMOgenerator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMOlayers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/layers.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/encoders.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/setup.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_sample.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/test_NeMO_voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/NeMO-NET/CNN/utils/NeMO_voc_generator.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/keras_fcn/models.py",
		"/C/Users/Rechant/Documents/GitHub/keras-fcn/voc2011/__init__.py",
		"/C/Users/Rechant/Documents/MachineLearning/mnist_mlp.py",
		"/C/Users/Rechant/AppData/Roaming/Sublime Text 3/Packages/Color Scheme - Default/Monokai.tmTheme",
		"/C/Users/Rechant/AppData/Roaming/Sublime Text 3/Packages/Theme - Default/Default.sublime-theme"
	],
	"find":
	{
		"height": 40.0
	},
	"find_in_files":
	{
		"height": 104.0,
		"where_history":
		[
			""
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"num_classes",
			"class_weights",
			"convert_all",
			"classifyback",
			"deepcopy",
			"get_config",
			"layer",
			"__init__",
			"super",
			"output_tensors",
			"lambda",
			"yield",
			"lrD",
			"pool_concat",
			"scaling",
			"labelkey",
			"summary",
			"img_to_array",
			"classifyback",
			"data_format",
			"_rescale",
			"uint8",
			"str(lr)",
			"optModel",
			"input_shape",
			"numpy",
			"except",
			"HEAD",
			"classes",
			"n",
			"space",
			"optModel",
			"space",
			"numpy",
			"trials",
			"batch_size",
			"iterator",
			"img_to_array",
			"temp.tif",
			"directoryIterator",
			"flow_from_direc",
			"flow_from",
			"fname",
			"index_array",
			"self.index_generator",
			"uint",
			"f.write",
			"get_file",
			"gray",
			"counter",
			"get_file",
			"load_seg",
			"datagen",
			"image_resample",
			"rescale",
			"offset",
			"index_generator",
			"IndexIterator",
			"IndexGenerator",
			"load_seg",
			"keras_fcn",
			"keras_func",
			"NeMO",
			"increment_var",
			"FCN",
			"index_generator",
			"IndexI",
			"indexiterator"
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": false,
		"replace_history":
		[
			"np"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 6,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "utils/NeMO_generator.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 27441,
						"regions":
						{
						},
						"selection":
						[
							[
								2666,
								2666
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 29.0,
						"zoom_level": 1.0
					},
					"stack_index": 6,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "utils/NeMO_layers.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 5869,
						"regions":
						{
						},
						"selection":
						[
							[
								447,
								447
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 90.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "utils/NeMO_blocks.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 21432,
						"regions":
						{
						},
						"selection":
						[
							[
								4890,
								4891
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 2,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 13.0,
						"translation.y": 1320.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "utils/NeMO_encoders.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 21361,
						"regions":
						{
						},
						"selection":
						[
							[
								12656,
								12656
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 8.0,
						"translation.y": 4295.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				},
				{
					"buffer": 4,
					"file": "utils/NeMO_decoders.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 6245,
						"regions":
						{
						},
						"selection":
						[
							[
								3899,
								3899
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 1755.0,
						"zoom_level": 1.0
					},
					"stack_index": 7,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "utils/NeMO_models.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 7823,
						"regions":
						{
						},
						"selection":
						[
							[
								3021,
								3021
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 537.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 6,
					"file": "AL_NeMO_hyperparamopt_VGG16DeepLabV2_256.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 6138,
						"regions":
						{
						},
						"selection":
						[
							[
								6138,
								6138
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 1744.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 7,
					"file": "utils/loadcoraldata_utils.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 28256,
						"regions":
						{
						},
						"selection":
						[
							[
								5814,
								5814
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 1686.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 23.0
	},
	"input":
	{
		"height": 0.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.find_results":
	{
		"height": 0.0
	},
	"pinned_build_system": "",
	"project": "NeMO-Net.sublime-project",
	"replace":
	{
		"height": 42.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": false,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 150.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
