{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image paths\n",
    "transect1 = '../Images/Transect 1 Hi-Res.tiff'\n",
    "transect1_truth = '../Images/Transect 1 Truth data.tif'\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread(transect1,cv2.IMREAD_UNCHANGED)\n",
    "img1_truth = cv2.imread(transect1_truth,cv2.IMREAD_UNCHANGED)\n",
    "                \n",
    "# Remap truth data\n",
    "if transect1_truth == '../Images/Transect 1 Truth data.tif':\n",
    "    img1_truth[img1_truth == 16] = 0  # Sand\n",
    "    img1_truth[img1_truth == 160] = 1 # Branching\n",
    "    img1_truth[img1_truth == 198] = 2 # Mounding\n",
    "    img1_truth[img1_truth == 38] = 3 # Rock\n",
    "\n",
    "'''Reformat image into input vector style\n",
    "Input:\n",
    "    imgset: set of images, N_images x nrow x ncol x n_channels\n",
    "    toremove: index of channel dimension to remove\n",
    "    labels: set of labels, N_images x N_labels (N_labels > 1 when we want to classify a number of pixels per image) \n",
    "    num_labels: number of possible labels for the entire dataset (4 for morphology, 2 for coral cover)\n",
    "Output:\n",
    "    dataset: set of vectorized images, N_images x (nrow*ncol) x (n_channels-n_toremove)\n",
    "    labels: set of vectorized labels in the form of logits, N_images x N_labels x num_labels\n",
    "'''\n",
    "def reformat(imgset, toremove, labels, num_labels):   \n",
    "    imgsetcut = imgset\n",
    "    if toremove is not None:\n",
    "        imgsetcut = np.delete(imgset,toremove,-1) # Remove specific 3rd dimension of array\n",
    "    print(imgsetcut.shape)\n",
    "    dataset = imgsetcut.reshape((-1, imgsetcut.shape[1]*imgsetcut.shape[2],imgsetcut.shape[3])).astype(np.float32)\n",
    "    labels = np.asarray([[(np.arange(num_labels) == labels[i,j]).astype(np.float32) for j in range(labels.shape[1])] for i in range(dataset.shape[0])])\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num_labels = 4\n",
    "image_size = 25 # side length of one sample image\n",
    "N_samples = 20000 # number of training samples per class (same as N_images)\n",
    "\n",
    "# Randomly select points\n",
    "crop_len = int(np.floor(image_size/2))\n",
    "img1_truth_crop = img1_truth[crop_len:img1_truth.shape[0]-crop_len, crop_len:img1_truth.shape[1]-crop_len]\n",
    "\n",
    "train_datasets = []\n",
    "train_labels = []\n",
    "for k in range(num_labels):\n",
    "    [i,j] = np.where(img1_truth_crop == k)\n",
    "    idx = np.asarray(random.sample(range(len(i)), N_samples)).astype(int)\n",
    "    train_datasets.append([img1[i[idx[nn]]:i[idx[nn]]+image_size, j[idx[nn]]:j[idx[nn]]+image_size, :] for nn in range(len(idx))])\n",
    "    train_labels.append([img1_truth_crop[i[idx[nn]], j[idx[nn]]] for nn in range(len(idx))])\n",
    "\n",
    "train_datasets = np.asarray(train_datasets) # train_datasets is in the format of num_labels x N_samples x nrows x ncols x n_channels\n",
    "train_labels = np.asarray(train_labels) # train_labels is in the format of num_labels x N_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 20000, 25, 25, 4)\n",
      "(4, 20000)\n",
      "[1 1 1 ..., 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# TEST STUFF\n",
    "print(train_datasets.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50, 50, 4)\n",
      "(2, 1)\n",
      "(2, 50, 50, 3)\n",
      "dict_keys([0, 2, 1, 3])\n",
      "dict_values([25298837, 7651431, 7360654, 551068])\n"
     ]
    }
   ],
   "source": [
    "# TEST STUFF\n",
    "temp = []\n",
    "temp.append(img1[100:150,100:150,:])\n",
    "temp.append(img1[101:151,101:151,:])\n",
    "temp = np.asarray(temp)\n",
    "templabels = np.asarray([[1],[2]])\n",
    "\n",
    "print(temp.shape)\n",
    "print(templabels.shape)\n",
    "temp2,temp2labels = reformat(temp,3,templabels,4)\n",
    "\n",
    "print(Counter(img1_truth.flatten()).keys()) # equals to list(set(words))\n",
    "print(Counter(img1_truth.flatten()).values()) # counts the elements' frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
